{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Rank.gen_word_dict as gwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_path = 'data/data.csv'\n",
    "to_path = 'data/trainSet/rank/dict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwd.word_dict_gengrator(from_path, to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_path = 'data/trainSet/rank/dict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data/trainSet/rank/tfidf/', '9130.pkl'), 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "data = data['doc']\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "corpus = data[400000*i:400000*(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = min(len(corpus)*0.0001+1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ' '.join(corpus)\n",
    "corpus = corpus.replace('。', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(corpus.split(' ')).items()\n",
    "word_wrap = filter(lambda x: x[1]>=limit, word_counts)\n",
    "word_set = {x[0]:x[1] for x in word_wrap}\n",
    "print('word_set size: ', len(word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_dict = {word: index + 1 for index, word in enumerate(list(word_set))}\n",
    "\n",
    "with open(os.path.join(to_path, 'tmp', '9130_'+str(i)+'_dictionary.dic'), 'wb') as fp:\n",
    "    pickle.dump(word_set, fp)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "word_count = defaultdict(lambda:0)\n",
    "\n",
    "for i in range(6):\n",
    "    with open(os.path.join(to_path,'tmp', '9130_'+str(i)+'_dictionary.dic'), 'rb') as fp:\n",
    "        tmp = pickle.load(fp)\n",
    "    for k,v in tmp.items():\n",
    "        word_count[k]+=v\n",
    "        \n",
    "word_count = [(k,v) for k,v in word_count.items()]\n",
    "print(len(word_count))\n",
    "word_dict = {word:index+1 for index, word in enumerate(list(word_count))}\n",
    "print(len(word_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(to_path, '9130_dictionary.dic'), 'wb') as fp:\n",
    "    pickle.dump(word_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##生成总词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "word_set = set()\n",
    "for i in [9001, 9012, 9047, 9130, 9299, 9461, 9483, 9542, 9705, 9771]:\n",
    "    with open(os.path.join('data/trainSet/rank/dict/', str(i)+'_dictionary.dic'), 'rb') as fp:\n",
    "        tmp = pickle.load(fp)\n",
    "        word_set |= set(tmp)\n",
    "\n",
    "word_dict = {word:index+1 for index, word in enumerate(list(word_set))}\n",
    "with open(os.path.join('data/trainSet/classifier/', 'dictionary.dic'),'wb') as fp:\n",
    "    pickle.dump(word_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
